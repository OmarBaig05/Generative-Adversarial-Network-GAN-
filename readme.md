# Simple GAN Implementation for Image Generation

## Project Overview
This project demonstrates the implementation of a Generative Adversarial Network (GAN) to generate realistic images. The GAN is trained on the "50K Celebrity Faces Image Dataset" available on Kaggle. The dataset contains celebrity face images, which are used to train the GAN to generate new, synthetic images of faces.

## Dataset
The dataset used for this project is the **50K Celebrity Faces Image Dataset**, which can be downloaded from [Kaggle](https://www.kaggle.com/datasets/farzadnekouei/50k-celebrity-faces-image-dataset). It contains a collection of high-quality images of celebrities.

### Dataset Preprocessing
1. **Image Loading**: Images are loaded from the dataset directory (`archive`).
2. **Resizing**: Images are resized to 64x64 pixels to ensure uniformity.
3. **Normalization**: Pixel values are normalized to the range [-1, 1], which is required for training the GAN.

The preprocessing ensures that the images are suitable for input into the GAN's generator and discriminator models.

## Introduction to GANs
Generative Adversarial Networks (GANs) are a type of neural network architecture introduced by Ian Goodfellow in 2014. GANs consist of two components:
1. **Generator**: Creates synthetic data (images in this case) from random noise.
2. **Discriminator**: Distinguishes between real data (from the dataset) and fake data (generated by the generator).

The generator and discriminator are trained simultaneously in a zero-sum game, where the generator tries to create realistic images to "fool" the discriminator, and the discriminator improves its ability to differentiate real from fake images.

### Workflow of GAN
1. **Input Noise**: The generator takes random noise as input and transforms it into synthetic images.
2. **Real vs Fake**: The discriminator evaluates both real images from the dataset and fake images from the generator, assigning a probability score.
3. **Loss Calculation**:
   - The generator's loss measures how well it can fool the discriminator.
   - The discriminator's loss measures its ability to correctly classify real and fake images.
4. **Backpropagation**: The gradients of the losses are used to update the weights of the generator and discriminator.
5. **Iterative Training**: This process is repeated for many epochs, gradually improving the quality of the generated images.

## Implementation Details

### Parameters
- **Image Dimensions**: 64x64 pixels
- **Batch Size**: 128 (64 for the generator, 64 for the discriminator)
- **Latent Dimension**: 100
- **Epochs**: 100

### Generator Model
The generator starts with a dense layer and progressively upsamples the input using transposed convolutions. Batch normalization and LeakyReLU activation are used for stability and better training.

### Discriminator Model
The discriminator is a convolutional neural network that classifies input images as real or fake. It uses LeakyReLU activations and dropout to prevent overfitting.

### Loss Functions
- **Generator Loss**: Binary cross-entropy between the discriminator's classification of fake images and the label "real".
- **Discriminator Loss**: Binary cross-entropy between its classification of real images as real and fake images as fake.

### Optimizers
Both models use the Adam optimizer with a learning rate of 0.0001.

## Training Process
1. **Dataset Loading**: The dataset is loaded and preprocessed.
2. **Training Steps**: For each batch of real images:
   - Generate fake images from noise.
   - Train the discriminator on both real and fake images.
   - Train the generator to produce images that can fool the discriminator.
3. **Loss Monitoring**: Generator and discriminator losses are printed for each epoch to monitor training progress.
4. **Image Generation**: After each epoch, synthetic images are generated and saved for visualization.

## Saving and Loading Models
To save and load the generator and discriminator models:
- **Saving**:
  ```python
  save_models(generator, discriminator, 'models')
  ```
- **Loading**:
  ```python
  generator, discriminator = load_models('models')
  ```

The models are stored in the `models` directory as `generator.h5` and `discriminator.h5`.

## Results
Generated images are saved after every epoch to visualize the generator's progress. These images demonstrate the improvement in quality as training progresses.

## Code Structure
- **Dataset Preprocessing**:
  - `load_and_preprocess_image`
  - `load_dataset`
- **Model Definitions**:
  - `build_generator`
  - `build_discriminator`
- **Training Functions**:
  - `train_step`
  - `train`
- **Utilities**:
  - `generate_and_save_images`
  - `save_models`
  - `load_models`

## Example Usage
1. Train the GAN:
   ```python
   train(train_dataset, EPOCHS)
   ```
2. Generate and save images:
   ```python
   generate_and_save_images(generator, epoch)
   ```
3. Save models:
   ```python
   save_models(generator, discriminator, 'models')
   ```
4. Load models:
   ```python
   generator, discriminator = load_models('models')
   ```

## Conclusion
This project demonstrates the implementation and training of a simple GAN for image generation. By training on the celebrity faces dataset, the generator learns to produce realistic face images. This implementation can be extended to other datasets and applications such as art generation, style transfer, and more.
